{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7bcf3b",
   "metadata": {},
   "source": [
    "#### Definition:\n",
    "Text summarization is the process of creating a shortened version of a text that captures its main points. There are two primary types of summarization:\n",
    "\n",
    "1. Extractive Summarization: Involves selecting important sentences, paragraphs, or sections directly from the original document to create the summary.\n",
    "2. Abstractive Summarization: Involves generating new sentences that convey the most important information from the original text, often rephrasing and condensing the content.\n",
    "\n",
    "#### Use Cases:\n",
    "1. News Summarization: Condensing news articles for quick reading.\n",
    "2. Document Summarization: Summarizing lengthy reports, research papers, or legal documents.\n",
    "3. Content Recommendation: Providing concise summaries of articles or books.\n",
    "4. Customer Support: Summarizing customer interactions or support tickets for quick resolution.\n",
    "#### Short Implementation:\n",
    "1. We will use the transformers library by Hugging Face to implement both extractive and abstractive summarization in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8006a6c",
   "metadata": {},
   "source": [
    "#### Step-by-Step Implementation:\n",
    "Install the necessary library:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152033c1",
   "metadata": {},
   "source": [
    "#### Import the libraries and load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47899ed6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the summarization pipeline\u001b[39;00m\n\u001b[0;32m      4\u001b[0m summarizer \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarization\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46acb7",
   "metadata": {},
   "source": [
    "#### Define the text to be summarized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence (AI) that focuses on the interaction \n",
    "between computers and humans through natural language. The ultimate goal of NLP is to enable computers to \n",
    "understand, interpret, and respond to human languages in a way that is both meaningful and useful. NLP is used \n",
    "in a variety of applications, including text translation, sentiment analysis, and speech recognition.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59612ff3",
   "metadata": {},
   "source": [
    "#### Generate the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "\n",
    "# Print the summary\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae423bf",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "1. Load the Summarization Pipeline: The pipeline function from the transformers library loads a pre-trained summarization model.\n",
    "2. Define the Text: The text to be summarized is defined as a string.\n",
    "3. Generate the Summary: The summarizer pipeline generates a summary of the text with specified constraints on the maximum and minimum length of the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f49c58",
   "metadata": {},
   "source": [
    "#### Advanced Abstractive Summarization:\n",
    "For more advanced abstractive summarization, you can use specific models like BART or T5 from the transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782426ff",
   "metadata": {},
   "source": [
    "#### Using BART for Summarization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a89e1ca",
   "metadata": {},
   "source": [
    "##### Load the BART model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31eb22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load pre-trained BART model and tokenizer\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6726a",
   "metadata": {},
   "source": [
    "#### Tokenize and summarize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0eaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "inputs = tokenizer.encode(\"summarize: \" + text, return_tensors='pt', max_length=1024, truncation=True)\n",
    "\n",
    "# Generate summary\n",
    "summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the summary\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b88ad3",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "Text summarization using pre-trained models from the transformers library is a powerful and straightforward approach to condense large texts into their key points. These models can be fine-tuned further to improve performance on specific types of documents or texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4939ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
