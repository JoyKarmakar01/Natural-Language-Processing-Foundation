{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e1760e",
   "metadata": {},
   "source": [
    "#### Definition:\n",
    "Text classification is the process of assigning predefined categories or labels to text data. It is a common natural language processing task that helps organize, structure, and categorize textual information.\n",
    "\n",
    "#### Types:\n",
    "1. Binary Classification: Classifying text into one of two categories (e.g., spam vs. not spam).\n",
    "2. Multiclass Classification: Classifying text into one of many categories (e.g., classifying news articles into different topics like sports, politics, entertainment).\n",
    "3. Multilabel Classification: Assigning multiple categories to a single text (e.g., a movie review could be tagged as both 'comedy' and 'romance').\n",
    "\n",
    "### Use Cases:\n",
    "1. Spam Detection: Identifying spam emails.\n",
    "2. Sentiment Analysis: Determining the sentiment (positive, negative, neutral) of text.\n",
    "3. Topic Classification: Categorizing news articles or documents by topics.\n",
    "4. Language Detection: Identifying the language of a given text.\n",
    "5. Intent Detection: Classifying user queries in chatbots to understand intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e212b",
   "metadata": {},
   "source": [
    "#### Short Implementation:\n",
    "We will use the sklearn library to implement a basic text classification using a Support Vector Machine (SVM) classifier.\n",
    "\n",
    "#### Step-by-Step Implementation:\n",
    "Install the necessary libraries:\n",
    "\n",
    "pip install scikit-learn\n",
    "#### Import libraries and load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Example data: List of texts and their corresponding labels\n",
    "data = {\n",
    "    'text': [\n",
    "        'I love this movie, it is fantastic!',\n",
    "        'The food was awful and the service was terrible.',\n",
    "        'What a beautiful day!',\n",
    "        'I hate this song, it is annoying.',\n",
    "        'The book is boring and too long.',\n",
    "        'This place is amazing, I will visit again!'\n",
    "    ],\n",
    "    'label': ['positive', 'negative', 'positive', 'negative', 'negative', 'positive']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0eebc",
   "metadata": {},
   "source": [
    "#### Preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145285f",
   "metadata": {},
   "source": [
    "#### Train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Support Vector Machine (SVM) classifier\n",
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac8dd3",
   "metadata": {},
   "source": [
    "#### Evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc42e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7836776",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "1. Load Data: The example data consists of texts and their corresponding sentiment labels (positive or negative).\n",
    "2. Preprocess Data: Split the data into training and test sets and convert the text data to TF-IDF features using TfidfVectorizer.\n",
    "3. Train Classifier: Train a Support Vector Machine (SVM) classifier using the TF-IDF features.\n",
    "4. Evaluate Model: Make predictions on the test set and evaluate the classifier's performance using accuracy and a classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf52ebc",
   "metadata": {},
   "source": [
    "#### Advanced Text Classification:\n",
    "For more advanced text classification tasks, you can use pre-trained language models like BERT or GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3a9b9",
   "metadata": {},
   "source": [
    "#### Using BERT for Text Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f78f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'text': [\n",
    "        'I love this movie, it is fantastic!',\n",
    "        'The food was awful and the service was terrible.',\n",
    "        'What a beautiful day!',\n",
    "        'I hate this song, it is annoying.',\n",
    "        'The book is boring and too long.',\n",
    "        'This place is amazing, I will visit again!'\n",
    "    ],\n",
    "    'label': [1, 0, 1, 0, 0, 1]  # 1 for positive, 0 for negative\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a2827",
   "metadata": {},
   "source": [
    "#### Preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9610820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Tokenize the text\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Convert to torch datasets\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Dataset(train_encodings, y_train.tolist())\n",
    "test_dataset = Dataset(test_encodings, y_test.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf720d9",
   "metadata": {},
   "source": [
    "#### Train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3afc33b",
   "metadata": {},
   "source": [
    "#### Evaluate the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca355dd8",
   "metadata": {},
   "source": [
    "#### Evaluate the classifier\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab3b03e",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "Text classification is a fundamental NLP task with various applications across different domains. Using pre-trained models like BERT can significantly enhance the performance of text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83ec5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
