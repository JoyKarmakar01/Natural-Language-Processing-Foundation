{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127ec638",
   "metadata": {},
   "source": [
    "#### Definition:\n",
    "Seq2Seq (Sequence-to-Sequence) is a type of model used for transforming one sequence into another. It is widely used in tasks where input and output are both sequences, such as machine translation, text summarization, and conversational models. A Seq2Seq model typically consists of an encoder and a decoder, both of which are usually implemented using RNNs, LSTMs, GRUs, or Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd5c33",
   "metadata": {},
   "source": [
    "#### Types:\n",
    "1. Encoder-Decoder RNN: Uses RNNs for both encoding the input sequence and decoding the output sequence.\n",
    "2. Encoder-Decoder with Attention: Enhances the basic Seq2Seq model with an attention mechanism to focus on different parts of the input sequence during decoding.\n",
    "3. Transformer-based Seq2Seq: Uses transformer architecture for both encoding and decoding, providing better performance on many tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fca45a",
   "metadata": {},
   "source": [
    "#### Use Cases:\n",
    "1. Machine Translation: Translating text from one language to another.\n",
    "2. Text Summarization: Summarizing long documents into shorter versions.\n",
    "3. Chatbots and Conversational Agents: Generating responses in a conversation.\n",
    "4. Image Captioning: Generating descriptive text for images.\n",
    "5. Speech Recognition: Converting speech to text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287caeb",
   "metadata": {},
   "source": [
    "#### Short Implementation:\n",
    "0. Seq2Seq with Attention for Machine Translation\n",
    "1. Step 1: Install Necessary Libraries\n",
    "2. Install torch and torchtext libraries for building and training the Seq2Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70661edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchtext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3c145",
   "metadata": {},
   "source": [
    "#### Step 2: Define the Seq2Seq Model\n",
    "Define the encoder, decoder, and attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c832ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hid_dim))\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden[-1].unsqueeze(1).repeat(1, src_len, 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = torch.sum(self.v * energy, dim=2)\n",
    "        return torch.softmax(attention, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, attention):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim + hid_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        attn_weights = self.attention(hidden, encoder_outputs)\n",
    "        attn_weights = attn_weights.unsqueeze(1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        weighted = torch.bmm(attn_weights, encoder_outputs).permute(1, 0, 2)\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8623a50b",
   "metadata": {},
   "source": [
    "#### Step 3: Train the Model\n",
    "Set up the training loop and train the Seq2Seq model on the translation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize encoder, decoder, and Seq2Seq model\n",
    "INPUT_DIM = 1000\n",
    "OUTPUT_DIM = 1000\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src, trg = batch.src, batch.trg\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# Training process (simplified)\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856d49c8",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "1. Encoder: Encodes the input sequence into a context vector (hidden and cell states).\n",
    "2. Attention: Computes attention weights to focus on different parts of the input sequence during decoding.\n",
    "3. Decoder: Decodes the context vector and generates the output sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e66c42",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "Seq2Seq models are powerful tools for transforming sequences from one domain to another. Adding an attention mechanism improves their ability to handle long sequences and capture relevant information, making them suitable for complex NLP tasks like machine translation and text summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d30dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
